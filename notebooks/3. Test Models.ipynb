{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a0b10cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "import traceback\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65167feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be loaded from: ../src/models\n",
      "Configured with 11 labels: ['addiction', 'adhd', 'anxiety', 'autism', 'bipolar', 'bpd', 'depression', 'ocd', 'psychosis', 'ptsd', 'suicide']\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = \"../src/models\"\n",
    "\n",
    "LABELS = [\n",
    "    'addiction',\n",
    "    'adhd',\n",
    "    'anxiety',\n",
    "    'autism',\n",
    "    'bipolar',\n",
    "    'bpd',\n",
    "    'depression',\n",
    "    'ocd',\n",
    "    'psychosis',\n",
    "    'ptsd',\n",
    "    'suicide'\n",
    "]\n",
    "\n",
    "LABEL2ID = {label: i for i, label in enumerate(LABELS)}\n",
    "ID2LABEL = {i: label for i, label in enumerate(LABELS)}\n",
    "\n",
    "print(f\"Models will be loaded from: {MODEL_DIR}\")\n",
    "print(f\"Configured with {len(LABELS)} labels: {LABELS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f17ff300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all models and vectorizers...\n",
      "-> Advanced models (SVC, SBERT-LR) loaded.\n",
      "-> Baseline models (LR, RF) loaded.\n",
      "-> SBERT model loaded.\n",
      "\n",
      "✅ All artifacts loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading all models and vectorizers...\")\n",
    "\n",
    "# Advanced models\n",
    "svc_model = joblib.load(os.path.join(MODEL_DIR, \"svc_model.pkl\"))\n",
    "tfidf_word = joblib.load(os.path.join(MODEL_DIR, \"tfidf_word.pkl\"))\n",
    "tfidf_char = joblib.load(os.path.join(MODEL_DIR, \"tfidf_char.pkl\"))\n",
    "lr_sbert = joblib.load(os.path.join(MODEL_DIR, \"lr_sbert.pkl\"))\n",
    "print(\"-> Advanced models (SVC, SBERT-LR) loaded.\")\n",
    "\n",
    "# Baseline models\n",
    "baseline_lr = joblib.load(os.path.join(MODEL_DIR, \"baseline_logistic_regression.pkl\"))\n",
    "baseline_rf = joblib.load(os.path.join(MODEL_DIR, \"baseline_random_forest.pkl\"))\n",
    "baseline_vectorizer = joblib.load(os.path.join(MODEL_DIR, \"tfidf_vectorizer.pkl\"))\n",
    "print(\"-> Baseline models (LR, RF) loaded.\")\n",
    "\n",
    "# Sentence Transformer (SBERT) model\n",
    "sbert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"-> SBERT model loaded.\")\n",
    "\n",
    "print(\"\\n✅ All artifacts loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1659df4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction function is defined.\n"
     ]
    }
   ],
   "source": [
    "def predict_top3(texts, weights=None):\n",
    "    if weights is None:\n",
    "        # Define the weights for combining model predictions\n",
    "        weights = {'svc': 0.4, 'sbert': 0.3, 'lr': 0.15, 'rf': 0.15}\n",
    "\n",
    "    results = []\n",
    "    try:\n",
    "        # --- Feature Generation ---\n",
    "        # 1. Advanced TF-IDF for SVC\n",
    "        X_word = tfidf_word.transform(texts)\n",
    "        X_char = tfidf_char.transform(texts)\n",
    "        X_advanced = hstack([X_word, X_char])\n",
    "\n",
    "        # 2. SBERT embeddings for SBERT-LR\n",
    "        embeddings = sbert_model.encode(texts, batch_size=32, convert_to_numpy=True)\n",
    "        \n",
    "        # 3. Baseline TF-IDF for baseline models\n",
    "        X_baseline = baseline_vectorizer.transform(texts)\n",
    "\n",
    "        # --- Probability Prediction ---\n",
    "        svc_probs = svc_model.predict_proba(X_advanced)\n",
    "        sbert_probs = lr_sbert.predict_proba(embeddings)\n",
    "        lr_probs = baseline_lr.predict_proba(X_baseline)\n",
    "        rf_probs = baseline_rf.predict_proba(X_baseline)\n",
    "\n",
    "        # --- Weighted Ensemble ---\n",
    "        ensemble_probs = (weights['svc'] * svc_probs +\n",
    "                          weights['sbert'] * sbert_probs +\n",
    "                          weights['lr'] * lr_probs +\n",
    "                          weights['rf'] * rf_probs)\n",
    "\n",
    "        # --- Process Results ---\n",
    "        for i, text in enumerate(texts):\n",
    "            final_probs = ensemble_probs[i]\n",
    "            top_indices = np.argsort(final_probs)[::-1][:3]\n",
    "            \n",
    "            top3 = [(ID2LABEL[idx], float(final_probs[idx])) for idx in top_indices]\n",
    "            \n",
    "            results.append({\n",
    "                'text': text[:100] + \"...\" if len(text) > 100 else text,\n",
    "                'predictions': top3\n",
    "            })\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ An error occurred during prediction: {e}\")\n",
    "        traceback.print_exc()\n",
    "        # Return an error message for all texts if one fails\n",
    "        results = [{'text': text, 'predictions': [('ERROR', 0.0)]} for text in texts]\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"Prediction function is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f52080b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ensemble prediction on sample texts...\n",
      "✅ Prediction complete.\n"
     ]
    }
   ],
   "source": [
    "# List of texts to test the model pipeline\n",
    "test_texts = [\n",
    "    \"I feel very anxious and can't sleep at night. My heart races constantly.\",\n",
    "    \"Lately I feel on top of the world, very energetic and happy, barely need sleep.\",\n",
    "    \"I find it hard to focus and get frustrated easily. I can't sit still for long.\",\n",
    "    \"I have these intrusive thoughts and I need to check things over and over again.\",\n",
    "    \"I feel empty inside and nothing brings me joy anymore. It's hard to even get out of bed.\",\n",
    "    \"My emotions are all over the place, my relationships are so intense and then they just end badly.\"\n",
    "]\n",
    "\n",
    "print(\"Running ensemble prediction on sample texts...\")\n",
    "prediction_results = predict_top3(test_texts)\n",
    "print(\"✅ Prediction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57afb936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Text #1 ---\n",
      "'I feel very anxious and can't sleep at night. My heart races constantly.'\n",
      "Top 3 Predictions:\n",
      "  1. ANXIETY      |██████████████░░░░░░|  71.2%\n",
      "  2. BIPOLAR      |█░░░░░░░░░░░░░░░░░░░|   5.0%\n",
      "  3. PSYCHOSIS    |░░░░░░░░░░░░░░░░░░░░|   3.2%\n",
      "------------------------------------------------------------\n",
      "--- Text #2 ---\n",
      "'Lately I feel on top of the world, very energetic and happy, barely need sleep.'\n",
      "Top 3 Predictions:\n",
      "  1. DEPRESSION   |███░░░░░░░░░░░░░░░░░|  19.2%\n",
      "  2. SUICIDE      |███░░░░░░░░░░░░░░░░░|  16.6%\n",
      "  3. BIPOLAR      |███░░░░░░░░░░░░░░░░░|  16.5%\n",
      "------------------------------------------------------------\n",
      "--- Text #3 ---\n",
      "'I find it hard to focus and get frustrated easily. I can't sit still for long.'\n",
      "Top 3 Predictions:\n",
      "  1. ADHD         |███████░░░░░░░░░░░░░|  39.7%\n",
      "  2. AUTISM       |███░░░░░░░░░░░░░░░░░|  18.4%\n",
      "  3. ANXIETY      |█░░░░░░░░░░░░░░░░░░░|   8.2%\n",
      "------------------------------------------------------------\n",
      "--- Text #4 ---\n",
      "'I have these intrusive thoughts and I need to check things over and over again.'\n",
      "Top 3 Predictions:\n",
      "  1. OCD          |███████████████░░░░░|  78.6%\n",
      "  2. PSYCHOSIS    |█░░░░░░░░░░░░░░░░░░░|   7.6%\n",
      "  3. ANXIETY      |░░░░░░░░░░░░░░░░░░░░|   2.0%\n",
      "------------------------------------------------------------\n",
      "--- Text #5 ---\n",
      "'I feel empty inside and nothing brings me joy anymore. It's hard to even get out of bed.'\n",
      "Top 3 Predictions:\n",
      "  1. DEPRESSION   |████████░░░░░░░░░░░░|  43.4%\n",
      "  2. PSYCHOSIS    |██░░░░░░░░░░░░░░░░░░|  10.4%\n",
      "  3. AUTISM       |█░░░░░░░░░░░░░░░░░░░|   8.9%\n",
      "------------------------------------------------------------\n",
      "--- Text #6 ---\n",
      "'My emotions are all over the place, my relationships are so intense and then they just end badly.'\n",
      "Top 3 Predictions:\n",
      "  1. BPD          |████████████░░░░░░░░|  63.3%\n",
      "  2. SUICIDE      |█░░░░░░░░░░░░░░░░░░░|   7.2%\n",
      "  3. AUTISM       |█░░░░░░░░░░░░░░░░░░░|   5.7%\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, result in enumerate(prediction_results, 1):\n",
    "    print(f\"--- Text #{i} ---\\n'{result['text']}'\")\n",
    "    print(\"Top 3 Predictions:\")\n",
    "    for rank, (label, confidence) in enumerate(result['predictions'], 1):\n",
    "        confidence_pct = confidence * 100\n",
    "        bar = \"█\" * int(confidence_pct / 5) + \"░\" * (20 - int(confidence_pct / 5))\n",
    "        print(f\"  {rank}. {label.upper():<12} |{bar}| {confidence_pct:5.1f}%\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bff892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual model analysis function is defined.\n"
     ]
    }
   ],
   "source": [
    "def analyze_individual_models(text):\n",
    "    print(f\"\\n🔬 Individual Model Analysis for:\\n'{text}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # --- Feature Prep ---\n",
    "    X_advanced = hstack([tfidf_word.transform([text]), tfidf_char.transform([text])])\n",
    "    embedding = sbert_model.encode([text], convert_to_numpy=True)\n",
    "    X_baseline = baseline_vectorizer.transform([text])\n",
    "\n",
    "    # --- Predictions ---\n",
    "    models_to_test = {\n",
    "        \"SVC (Advanced TF-IDF)\": (svc_model, X_advanced),\n",
    "        \"SBERT-LR\": (lr_sbert, embedding),\n",
    "        \"Baseline LR (TF-IDF)\": (baseline_lr, X_baseline),\n",
    "        \"Baseline RF (TF-IDF)\": (baseline_rf, X_baseline)\n",
    "    }\n",
    "\n",
    "    for model_name, (model, features) in models_to_test.items():\n",
    "        probs = model.predict_proba(features)[0]\n",
    "        prediction_idx = np.argmax(probs)\n",
    "        prediction_label = ID2LABEL[prediction_idx]\n",
    "        confidence = probs[prediction_idx]\n",
    "        \n",
    "        print(f\"-> {model_name}:\")\n",
    "        print(f\"   Prediction: {prediction_label.upper()} ({confidence:.2%})\")\n",
    "\n",
    "print(\"Individual model analysis function is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c31ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 Individual Model Analysis for:\n",
      "'I can't stop checking if I locked the door and washing my hands repeatedly'\n",
      "============================================================\n",
      "-> SVC (Advanced TF-IDF):\n",
      "   Prediction: OCD (77.75%)\n",
      "-> SBERT-LR:\n",
      "   Prediction: OCD (85.64%)\n",
      "-> Baseline LR (TF-IDF):\n",
      "   Prediction: OCD (53.09%)\n",
      "-> Baseline RF (TF-IDF):\n",
      "   Prediction: AUTISM (10.63%)\n"
     ]
    }
   ],
   "source": [
    "# Choose any text you want to analyze in detail\n",
    "sample_text_for_analysis = \"I can't stop checking if I locked the door and washing my hands repeatedly\"\n",
    "\n",
    "analyze_individual_models(sample_text_for_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfabe13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
